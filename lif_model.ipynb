{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import zip_longest\n",
    "SEED = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SingleLayerSNN:\n",
    "    \n",
    "    def __init__(self, inputs, weights, trainings, Cm=4, Rm=5, V_thresh=30, V_rest=-65, V_spike=80, dT=0.01, rate=1):\n",
    "        \"\"\"\n",
    "        Runs a LIF simulation on neuron and returns outputted voltage\n",
    "\n",
    "                Parameters:\n",
    "                        inputs (double[][][]): A 3d numpy array of the input voltages per timestep\n",
    "                        weights (double[]): A numpy array of initial weights\n",
    "                        outputs (double[][][]): A 3d numpy array of the output voltages per timestep used for teaching neuron\n",
    "                Returns:\n",
    "                        None\n",
    "        \"\"\"\n",
    "\n",
    "        self.inputs = inputs\n",
    "        self.weights = weights\n",
    "        self.trainings = trainings\n",
    "        self.Cm = Cm\n",
    "        self.Rm = Rm\n",
    "        self.V_thresh = V_thresh\n",
    "        self.V_rest = V_rest\n",
    "        self.V_spike = V_spike\n",
    "        self.dT = dT # ms\n",
    "        self.rate = rate # sec\n",
    "        self._LIF_spikes = 0                    \n",
    "        \n",
    "    def LIF(self, I):\n",
    "        \"\"\"\n",
    "        Runs a LIF simulation on neuron and returns outputted voltage\n",
    "\n",
    "                Parameters:\n",
    "                        I (double[]): A numpy array of input voltages in mV\n",
    "\n",
    "                Returns:\n",
    "                        V (double[]): A numpy array of the output voltages in mV\n",
    "        \"\"\"\n",
    "        total_time = (I.size) * self.dT\n",
    "\n",
    "        # an array of time\n",
    "        time = np.arange(0, total_time, self.dT)\n",
    "\n",
    "        # default voltage list set to resting volatage of -65mV\n",
    "        V = (self.V_rest) * np.ones(len(time))\n",
    "\n",
    "        did_spike = False\n",
    "\n",
    "        # function member variable to track spikes\n",
    "        self._LIF_spikes = 0\n",
    "\n",
    "        for t in range(len(time)):\n",
    "            # using \"I - V(t)/Rm = Cm * dV/dT\"\n",
    "            dV = (I[t] - (V[t - 1] - self.V_rest) / self.Rm) / self.Cm\n",
    "\n",
    "            # reset membrane potential if neuron spiked last tick\n",
    "            if did_spike:\n",
    "                V[t] = self.V_rest + dV * self.dT\n",
    "            else:\n",
    "                V[t] = V[t - 1] + dV * self.dT\n",
    "\n",
    "            # check if membrane voltage exceeded threshold (spike)\n",
    "            if V[t] > self.V_thresh:\n",
    "                did_spike = True\n",
    "                # set the last step to spike value\n",
    "                V[t] = self.V_spike\n",
    "                self._LIF_spikes += 1\n",
    "            else:\n",
    "                did_spike = False\n",
    "\n",
    "        return V\n",
    "    \n",
    "    def voltage_to_output(self, V_input):\n",
    "        V_output = np.array([])\n",
    "        for v in V_input:\n",
    "            V_output = np.append(V_output, 0 if v < self.V_spike else self.V_spike)\n",
    "        return V_output\n",
    "    \n",
    "    def voltage_to_spike_rate(self, voltages, dT=None, rate=None):\n",
    "        if not dT:\n",
    "            dT = self.dT\n",
    "        if not rate:\n",
    "            rate = self.rate\n",
    "            \n",
    "#         print('voltages', voltages)\n",
    "        \n",
    "        def cond(V):\n",
    "            return V >= self.V_spike\n",
    "        \n",
    "        spike_count = sum(cond(V) for V in voltages)\n",
    "        \n",
    "#         print('spike_count', spike_count)\n",
    "        \n",
    "        total_time_dT = len(voltages) * dT\n",
    "#         print(f'total_time_dT: {total_time_dT} ({dT}ms)')\n",
    "        \n",
    "        spikes_per_dT = spike_count / total_time_dT\n",
    "#         print(f'spikes_per_ms: {spikes_per_dT} (spikes/ms)')\n",
    "        \n",
    "        return spikes_per_dT * 1000 * rate     \n",
    "    \n",
    "    # returns the voltages of input and output neurons\n",
    "    def feed_forward(self, inputs, trainings=[]):\n",
    "        all_input_voltages = []\n",
    "        all_output_voltages = []\n",
    "        \n",
    "        for input_set, training_set in zip_longest(inputs, trainings):\n",
    "            input_voltages = []\n",
    "            for V_input in input_set:\n",
    "                input_voltages.append(self.LIF(V_input))\n",
    "                \n",
    "            output_inputs = []\n",
    "            input_outputs = [] # DEBUG ONLY\n",
    "            for weight_set in weights.T:\n",
    "                weighted_sum = np.zeros(len(input_set[0]))\n",
    "                for V_input, weight in zip(input_voltages, weight_set):\n",
    "                    # filter for spikes b/c a neuron only outputs if it spikes\n",
    "                    input_output = self.voltage_to_output(V_input)\n",
    "                    input_outputs.append(input_output) # DEBUG ONLY\n",
    "                    weighted = input_output * weight\n",
    "                    weighted_sum = np.add(weighted_sum, weighted)\n",
    "            \n",
    "                output_inputs.append(weighted_sum)\n",
    "            \n",
    "            input_voltages = np.array(input_voltages)\n",
    "            input_outputs = np.array(input_outputs)\n",
    "            output_inputs = np.array(output_inputs)\n",
    "            \n",
    "#             print('input_voltages:')\n",
    "#             print(input_voltages)\n",
    "#             print('input_outputs:')\n",
    "#             print(input_outputs)\n",
    "#             print('output_inputs:')\n",
    "#             print(output_inputs)\n",
    "#             print('training_set:')\n",
    "#             print(training_set)\n",
    "            \n",
    "            all_input_voltages.append(input_voltages)\n",
    "            \n",
    "            # inject training voltage if exists\n",
    "            if isinstance(training_set, (list, np.ndarray)):\n",
    "                for i, (output_input, training_input) in enumerate(zip(output_inputs, training_set)):\n",
    "                    if isinstance(training_input, (list, np.ndarray)):\n",
    "                        padded_training_input = np.pad(training_input, (0, len(output_inputs) - len(training_set)), \"constant\")\n",
    "                        output_inputs[i] = output_input + padded_training_input\n",
    "                \n",
    "#             print('output_inputs after injecting training current')\n",
    "#             print(output_inputs)\n",
    "        \n",
    "            # run LIF on output neurons\n",
    "            output_voltages = []\n",
    "            for V_input in output_inputs:\n",
    "                output_voltages.append(self.LIF(V_input))\n",
    "                            \n",
    "            output_voltages = np.array(output_voltages)\n",
    "            all_output_voltages.append(output_voltages)\n",
    "            \n",
    "#             print('output_voltages:')\n",
    "#             print(output_voltages)\n",
    "        \n",
    "        all_input_voltages = np.array(all_input_voltages)\n",
    "        all_output_voltages = np.array(all_output_voltages)\n",
    "        \n",
    "        return all_input_voltages, all_output_voltages\n",
    "                \n",
    "                    \n",
    "    def train(self, epochs=100):\n",
    "        a_corr = 0.0002\n",
    "        w_max = 500\n",
    "        w_decay = 2\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(f'Epoch: {epoch + 1}')\n",
    "            \n",
    "            all_input_voltages, all_output_voltages = self.feed_forward(self.inputs, self.trainings)\n",
    "            \n",
    "            # debug info\n",
    "#             print()\n",
    "#             print('------------------------------------------------')\n",
    "#             print('all_input_voltages:')\n",
    "#             print(all_input_voltages)\n",
    "#             print('all_output_voltages:')\n",
    "#             print(all_output_voltages)\n",
    "            \n",
    "#             print('weights:')\n",
    "#             print(self.weights)\n",
    "            \n",
    "            # apply learning rule\n",
    "            for input_voltages, output_voltages in zip(all_input_voltages, all_output_voltages):\n",
    "#                 print('input_voltages', input_voltages)\n",
    "                for i, (input_voltage_set, weight_set) in enumerate(zip(input_voltages, self.weights)):\n",
    "#                     print('input_voltage_set', input_voltage_set)\n",
    "                    input_rate = self.voltage_to_spike_rate(input_voltage_set)\n",
    "#                     print(f'input_rate {i}:', input_rate)\n",
    "        \n",
    "                    for j, (output_voltage_set, weight) in enumerate(zip(output_voltages, weight_set)):\n",
    "                        output_rate = self.voltage_to_spike_rate(output_voltage_set)\n",
    "#                         print(f'\\toutput_rate {j}:', output_rate)\n",
    "                        \n",
    "                        # adjust the weight using Hebb with decay\n",
    "                        weight_change = a_corr * input_rate * output_rate - w_decay\n",
    "#                         print('\\told weight', weight)\n",
    "#                         print('\\tweight_change:', weight_change)\n",
    "                        \n",
    "                        if weight + weight_change < 0:\n",
    "                            weights[i][j] = 0\n",
    "                        elif weight + weight_change > w_max:\n",
    "                            weights[i][j] = w_max\n",
    "                        else:\n",
    "                            weights[i][j] = weight + weight_change\n",
    "                            \n",
    "#                         print('\\tnew weight', weights[i][j], '\\n')\n",
    "                        \n",
    "            print(self.weights)\n",
    "            \n",
    "            # plot data\n",
    "#             for i, (input_voltages, output_voltages) in enumerate(zip(all_input_voltages, all_output_voltages)):\n",
    "#                 plt.figure(figsize=(20,10))\n",
    "#                 plt.suptitle(f'Input: {i + 1}', fontsize=18)\n",
    "#                 for input_voltage in input_voltages:\n",
    "#                     plt.plot(input_voltage, 'b:', alpha=.5)\n",
    "                    \n",
    "#                 for output_voltage in output_voltages:\n",
    "#                     plt.plot(output_voltage, 'r--', alpha=.5)\n",
    "                \n",
    "#             plt.show()\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        all_input_voltages, all_output_voltages = self.feed_forward(self.inputs)\n",
    "        print('all_output_voltages')\n",
    "        print(all_output_voltages)\n",
    "        for x, (input_voltages, output_voltages) in enumerate(zip(all_input_voltages, all_output_voltages)):\n",
    "            print('input set:', x)\n",
    "            for i, input_voltage_set in enumerate(input_voltages):\n",
    "                print(f'\\tinput {i}: {self.voltage_to_spike_rate(input_voltage_set)} spikes/{self.rate}s')\n",
    "            print()\n",
    "            for i, output_voltage_set in enumerate(output_voltages):\n",
    "                print(f'\\toutput {i}: {self.voltage_to_spike_rate(output_voltage_set)} spikes/{self.rate}s')\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[[3.62 3.62]\n",
      " [0.   9.24]\n",
      " [3.62 4.12]\n",
      " [0.   8.74]]\n",
      "Epoch: 2\n",
      "[[ 6.74  6.74]\n",
      " [ 0.   17.48]\n",
      " [ 6.74  7.24]\n",
      " [ 0.   16.98]]\n",
      "Epoch: 3\n",
      "[[ 9.86  9.86]\n",
      " [ 0.   25.72]\n",
      " [ 9.86 10.36]\n",
      " [ 0.   25.22]]\n",
      "Epoch: 4\n",
      "[[12.98 12.98]\n",
      " [ 0.   33.96]\n",
      " [12.98 13.48]\n",
      " [ 0.   33.46]]\n",
      "Epoch: 5\n",
      "[[16.1 16.1]\n",
      " [ 0.  42.2]\n",
      " [16.1 16.6]\n",
      " [ 0.  41.7]]\n",
      "Epoch: 6\n",
      "[[19.22 19.22]\n",
      " [ 0.   50.44]\n",
      " [19.22 19.72]\n",
      " [ 0.   49.94]]\n",
      "Epoch: 7\n",
      "[[22.34 22.34]\n",
      " [ 0.   58.68]\n",
      " [22.34 22.84]\n",
      " [ 0.   58.18]]\n",
      "Epoch: 8\n",
      "[[25.46 25.46]\n",
      " [ 0.   66.92]\n",
      " [25.46 25.96]\n",
      " [ 0.   66.42]]\n",
      "Epoch: 9\n",
      "[[28.58 28.58]\n",
      " [ 0.   75.16]\n",
      " [28.58 29.08]\n",
      " [ 0.   74.66]]\n",
      "Epoch: 10\n",
      "[[31.7 31.7]\n",
      " [ 0.  83.4]\n",
      " [31.7 32.2]\n",
      " [ 0.  82.9]]\n",
      "Epoch: 11\n",
      "[[34.82 34.82]\n",
      " [ 0.   91.64]\n",
      " [34.82 35.32]\n",
      " [ 0.   91.14]]\n",
      "Epoch: 12\n",
      "[[37.94 37.94]\n",
      " [ 0.   99.88]\n",
      " [37.94 38.44]\n",
      " [ 0.   99.38]]\n",
      "Epoch: 13\n",
      "[[ 41.06  41.06]\n",
      " [  0.   108.12]\n",
      " [ 41.06  41.56]\n",
      " [  0.   107.62]]\n",
      "Epoch: 14\n",
      "[[ 44.18  44.18]\n",
      " [  0.   116.36]\n",
      " [ 44.18  44.68]\n",
      " [  0.   115.86]]\n",
      "Epoch: 15\n",
      "[[ 47.3  47.3]\n",
      " [  0.  124.6]\n",
      " [ 47.3  47.8]\n",
      " [  0.  124.1]]\n",
      "Epoch: 16\n",
      "[[ 50.42  50.42]\n",
      " [  0.   132.84]\n",
      " [ 50.42  50.92]\n",
      " [  0.   132.34]]\n",
      "Epoch: 17\n",
      "[[ 53.54  53.54]\n",
      " [  0.   141.08]\n",
      " [ 53.54  54.04]\n",
      " [  0.   140.58]]\n",
      "Epoch: 18\n",
      "[[ 56.66  56.66]\n",
      " [  0.   149.32]\n",
      " [ 56.66  57.16]\n",
      " [  0.   148.82]]\n",
      "Epoch: 19\n",
      "[[ 59.78  59.78]\n",
      " [  0.   157.56]\n",
      " [ 59.78  60.28]\n",
      " [  0.   157.06]]\n",
      "Epoch: 20\n",
      "[[ 62.9  62.9]\n",
      " [  0.  165.8]\n",
      " [ 62.9  63.4]\n",
      " [  0.  165.3]]\n",
      "Epoch: 21\n",
      "[[ 66.02  66.02]\n",
      " [  0.   174.04]\n",
      " [ 66.02  66.52]\n",
      " [  0.   173.54]]\n",
      "Epoch: 22\n",
      "[[ 69.14  69.14]\n",
      " [  0.   182.28]\n",
      " [ 69.14  69.64]\n",
      " [  0.   181.78]]\n",
      "Epoch: 23\n",
      "[[ 72.26  72.26]\n",
      " [  0.   190.52]\n",
      " [ 72.26  72.76]\n",
      " [  0.   190.02]]\n",
      "Epoch: 24\n",
      "[[ 75.38        76.23333333]\n",
      " [  0.         198.76      ]\n",
      " [ 75.38        76.73333333]\n",
      " [  0.         198.26      ]]\n",
      "Epoch: 25\n",
      "[[ 78.5         80.20666667]\n",
      " [  0.         207.        ]\n",
      " [ 78.5         80.70666667]\n",
      " [  0.         206.5       ]]\n",
      "Epoch: 26\n",
      "[[ 81.62  84.18]\n",
      " [  0.   215.24]\n",
      " [ 81.62  84.68]\n",
      " [  0.   214.74]]\n",
      "Epoch: 27\n",
      "[[ 84.74        88.15333333]\n",
      " [  0.         223.48      ]\n",
      " [ 84.74        88.65333333]\n",
      " [  0.         222.98      ]]\n",
      "Epoch: 28\n",
      "[[ 87.86        92.12666667]\n",
      " [  0.         231.72      ]\n",
      " [ 87.86        92.62666667]\n",
      " [  0.         231.22      ]]\n",
      "Epoch: 29\n",
      "[[ 90.98  96.1 ]\n",
      " [  0.   239.96]\n",
      " [ 90.98  96.6 ]\n",
      " [  0.   239.46]]\n",
      "Epoch: 30\n",
      "[[ 94.1        100.07333333]\n",
      " [  0.         248.2       ]\n",
      " [ 94.1        100.57333333]\n",
      " [  0.         247.7       ]]\n",
      "Epoch: 31\n",
      "[[ 97.22       104.04666667]\n",
      " [  0.         256.44      ]\n",
      " [ 97.22       104.54666667]\n",
      " [  0.         255.94      ]]\n",
      "Epoch: 32\n",
      "[[100.34       108.87333333]\n",
      " [  0.         264.68      ]\n",
      " [100.34       109.37333333]\n",
      " [  0.         264.18      ]]\n",
      "Epoch: 33\n",
      "[[103.46 113.7 ]\n",
      " [  0.   272.92]\n",
      " [103.46 114.2 ]\n",
      " [  0.   272.42]]\n",
      "Epoch: 34\n",
      "[[106.58       118.52666667]\n",
      " [  0.         281.16      ]\n",
      " [106.58       119.02666667]\n",
      " [  0.         280.66      ]]\n",
      "Epoch: 35\n",
      "[[109.7        123.35333333]\n",
      " [  0.         289.4       ]\n",
      " [109.7        123.85333333]\n",
      " [  0.         288.9       ]]\n",
      "Epoch: 36\n",
      "[[112.82 128.18]\n",
      " [  0.   297.64]\n",
      " [112.82 128.68]\n",
      " [  0.   297.14]]\n",
      "Epoch: 37\n",
      "[[115.94       133.00666667]\n",
      " [  0.         305.88      ]\n",
      " [115.94       133.50666667]\n",
      " [  0.         305.38      ]]\n",
      "Epoch: 38\n",
      "[[119.06       137.83333333]\n",
      " [  0.         314.12      ]\n",
      " [119.06       138.33333333]\n",
      " [  0.         313.62      ]]\n",
      "Epoch: 39\n",
      "[[122.18       143.51333333]\n",
      " [  0.         322.36      ]\n",
      " [122.18       144.01333333]\n",
      " [  0.         321.86      ]]\n",
      "Epoch: 40\n",
      "[[125.3        149.19333333]\n",
      " [  0.         330.6       ]\n",
      " [125.3        149.69333333]\n",
      " [  0.         330.1       ]]\n",
      "Epoch: 41\n",
      "[[128.42       154.87333333]\n",
      " [  0.         338.84      ]\n",
      " [128.42       155.37333333]\n",
      " [  0.         338.34      ]]\n",
      "Epoch: 42\n",
      "[[131.54       160.55333333]\n",
      " [  0.         347.08      ]\n",
      " [131.54       161.05333333]\n",
      " [  0.         346.58      ]]\n",
      "Epoch: 43\n",
      "[[134.66       166.23333333]\n",
      " [  0.         355.32      ]\n",
      " [134.66       166.73333333]\n",
      " [  0.         354.82      ]]\n",
      "Epoch: 44\n",
      "[[137.78       171.91333333]\n",
      " [  0.         363.56      ]\n",
      " [137.78       172.41333333]\n",
      " [  0.         363.06      ]]\n",
      "Epoch: 45\n",
      "[[140.9        177.59333333]\n",
      " [  0.         371.8       ]\n",
      " [140.9        178.09333333]\n",
      " [  0.         371.3       ]]\n",
      "Epoch: 46\n",
      "[[144.87333333 183.27333333]\n",
      " [  0.         380.04      ]\n",
      " [144.87333333 183.77333333]\n",
      " [  0.         379.54      ]]\n",
      "Epoch: 47\n",
      "[[148.84666667 188.95333333]\n",
      " [  0.         388.28      ]\n",
      " [148.84666667 189.45333333]\n",
      " [  0.         387.78      ]]\n",
      "Epoch: 48\n",
      "[[152.82       194.63333333]\n",
      " [  0.         396.52      ]\n",
      " [152.82       195.13333333]\n",
      " [  0.         396.02      ]]\n",
      "Epoch: 49\n",
      "[[156.79333333 200.31333333]\n",
      " [  0.         404.76      ]\n",
      " [156.79333333 200.81333333]\n",
      " [  0.         404.26      ]]\n",
      "Epoch: 50\n",
      "[[160.76666667 205.99333333]\n",
      " [  0.         413.        ]\n",
      " [160.76666667 206.49333333]\n",
      " [  0.         412.5       ]]\n",
      "all_output_voltages\n",
      "[[[-65.         -65.         -65.         ... -65.05677099 -65.0567426\n",
      "   -65.05671423]\n",
      "  [-65.         -65.         -65.         ... -65.05677099 -65.0567426\n",
      "   -65.05671423]]\n",
      "\n",
      " [[-65.         -65.         -65.         ... -39.87825191 -39.89081278\n",
      "   -39.90336738]\n",
      "  [-65.         -65.         -65.         ... -65.05677099 -65.0567426\n",
      "   -65.05671423]]\n",
      "\n",
      " [[-65.         -65.         -65.         ... -39.87825191 -39.89081278\n",
      "   -39.90336738]\n",
      "  [-65.         -65.         -65.         ... -65.05677099 -65.0567426\n",
      "   -65.05671423]]\n",
      "\n",
      " [[-65.         -65.         -65.         ... -65.         -65.\n",
      "   -65.        ]\n",
      "  [-65.         -65.         -65.         ... -65.05677099 -65.0567426\n",
      "   -65.05671423]]]\n",
      "input set: 0\n",
      "\tinput 0: 160.0 spikes/1s\n",
      "\tinput 1: 0.0 spikes/1s\n",
      "\tinput 2: 160.0 spikes/1s\n",
      "\tinput 3: 0.0 spikes/1s\n",
      "\n",
      "\toutput 0: 80.0 spikes/1s\n",
      "\toutput 1: 80.0 spikes/1s\n",
      "\n",
      "input set: 1\n",
      "\tinput 0: 160.0 spikes/1s\n",
      "\tinput 1: 0.0 spikes/1s\n",
      "\tinput 2: 0.0 spikes/1s\n",
      "\tinput 3: 160.0 spikes/1s\n",
      "\n",
      "\toutput 0: 26.666666666666668 spikes/1s\n",
      "\toutput 1: 160.0 spikes/1s\n",
      "\n",
      "input set: 2\n",
      "\tinput 0: 0.0 spikes/1s\n",
      "\tinput 1: 160.0 spikes/1s\n",
      "\tinput 2: 160.0 spikes/1s\n",
      "\tinput 3: 0.0 spikes/1s\n",
      "\n",
      "\toutput 0: 26.666666666666668 spikes/1s\n",
      "\toutput 1: 160.0 spikes/1s\n",
      "\n",
      "input set: 3\n",
      "\tinput 0: 0.0 spikes/1s\n",
      "\tinput 1: 160.0 spikes/1s\n",
      "\tinput 2: 0.0 spikes/1s\n",
      "\tinput 3: 160.0 spikes/1s\n",
      "\n",
      "\toutput 0: 0.0 spikes/1s\n",
      "\toutput 1: 160.0 spikes/1s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "units_of_time = 3750\n",
    "inputs = np.array([\n",
    "    [[80] * units_of_time, [0] * units_of_time, [80] * units_of_time, [0] * units_of_time], # x: T, y: T --> T\n",
    "    [[80] * units_of_time, [0] * units_of_time, [0] * units_of_time, [80] * units_of_time], # x: T, y: F --> F\n",
    "    [[0] * units_of_time, [80] * units_of_time, [80] * units_of_time, [0] * units_of_time], # x: F, y: T --> F\n",
    "    [[0] * units_of_time, [80] * units_of_time, [0] * units_of_time, [80] * units_of_time], # x: F, y: F --> F\n",
    "])\n",
    "\n",
    "weights = np.array([\n",
    "    [.5, .5], \n",
    "    [.5, .5],\n",
    "    [.5, .5],\n",
    "    [.5, .5],\n",
    "])\n",
    "\n",
    "# current that gets injected to the output neurons\n",
    "trainings = np.array([\n",
    "    [[80] * units_of_time, [0] * units_of_time], # T\n",
    "    [[0] * units_of_time, [80] * units_of_time], # F\n",
    "    [[0] * units_of_time, [80] * units_of_time], # F\n",
    "    [[0] * units_of_time, [80] * units_of_time], # f\n",
    "])\n",
    "\n",
    "and_network = SingleLayerSNN(inputs=inputs, weights=weights, trainings=trainings)\n",
    "\n",
    "and_network.train(50)\n",
    "and_network.predict(inputs)\n",
    "\n",
    "# and_network.voltage_to_spike_rate([80, 80, 80, 80, 80, 0, 0, 0, 0, 0, 80, 80], dT=0.01, rate=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 3 4]\n",
      "1 1 2\n",
      "2 2 3\n",
      "3 0 5\n",
      "4 0 None\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([1, 2])\n",
    "b = np.pad(b, (0, len(a) - len(b)), \"constant\")\n",
    "c = [2, 3, 5]\n",
    "\n",
    "print(a + b)\n",
    "\n",
    "for x, y, z in zip_longest(a, b, c):\n",
    "    print(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
